<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>A Simple Linear Regression from scratch | DomsDev Data-Science</title>



<link href="https://domsdev.github.io/Data-science-blog/index.xml" rel="alternate" type="application/rss+xml" title="DomsDev Data-Science">

<link rel="stylesheet" href="https://domsdev.github.io/Data-science-blog/css/style.css"><link rel='stylesheet' href='https://domsdev.github.io/Data-science-blog/css/custom.css'><link rel="apple-touch-icon" sizes="180x180" href="https://domsdev.github.io/Data-science-blog/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://domsdev.github.io/Data-science-blog/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://domsdev.github.io/Data-science-blog/favicon-16x16.png">
<link rel="manifest" href="https://domsdev.github.io/Data-science-blog/site.webmanifest">
<link rel="mask-icon" href="https://domsdev.github.io/Data-science-blog/safari-pinned-tab.svg" color="#5bbad5">
<link rel="canonical" href="https://domsdev.github.io/Data-science-blog/post/a_simple_linear_regression_from_scratch/">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMH2VJY863"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-NMH2VJY863', { 'anonymize_ip': false });
}
</script>

</head>
<body>

<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="https://domsdev.github.io/Data-science-blog/">
          <h1 id="nav-heading" class="title is-4">DomsDev Data-Science</h1>
        </a>
      </div>
      <div class="nav-right">
        <nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="linkedin" href='https://linkedin.com/in/dominique-pothin-dev/'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path stroke-width="1.8" d="m5.839218,4.101561c0,1.211972 -0.974141,2.194011 -2.176459,2.194011s-2.176459,-0.982039 -2.176459,-2.194011c0,-1.211094 0.974141,-2.194011 2.176459,-2.194011s2.176459,0.982917 2.176459,2.194011zm0.017552,3.94922l-4.388022,0l0,14.04167l4.388022,0l0,-14.04167zm7.005038,0l-4.359939,0l0,14.04167l4.360816,0l0,-7.370999c0,-4.098413 5.291077,-4.433657 5.291077,0l0,7.370999l4.377491,0l0,-8.89101c0,-6.915523 -7.829986,-6.66365 -9.669445,-3.259423l0,-1.891237z"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="github" href='https://github.com/Domsdev'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="email" href='mailto:domsdev.sender@gmail.com'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
    <polyline points="22,6 12,13 2,6"/>
    
  </svg></i>
            </span>
          </a></nav>
      </div>
    </nav>

    <nav class="nav">
      

      
    </nav>

  </div>
  <script src="https://domsdev.github.io/Data-science-blog/js/navicon-shift.js"></script>
</section>
<section class="section">
  <div class="container">
    <div class="subtitle tags is-6 is-pulled-right">
      
      
<a class="subtitle is-6" href="https://domsdev.github.io/Data-science-blog/tags/linear-regression/">#Linear Regression</a>



  
  | <a class="subtitle is-6" href="https://domsdev.github.io/Data-science-blog/tags/from-scratch/">#From Scratch</a>
  


      
    </div>
    <h2 class="subtitle is-6">September 9, 2020</h2>
    <h1 class="title">A Simple Linear Regression from scratch</h1>
    
    <div class="content">
      <!-- raw HTML omitted -->
<h2 id="objective">Objective:</h2>
<p>The goal is to create a salary estimator based on years of experience of the employees of an anonymous company, using a simple Linear Regression Model build from scratch applied on &ldquo;Salary_Data.csv&rdquo; Kaggle&rsquo;s dataset. Then I will compare the performance of the model against the prebuilt Sklearn linear regression model.<!-- raw HTML omitted --></p>
<p>I won&rsquo;t explain theory here, only background basic equations needed for code understanding.</p>
<p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/linear_regression.png#c" alt="png"></p>
<hr>
<h2 id="table-of-contents">Table of contents</h2>
<ol>
<li>Dataset</li>
<li>Linear model definition</li>
<li>Loss function definition</li>
<li>Gradient definition</li>
<li>Gradient descent algorithm</li>
<li>Training the model on data</li>
<li>Model evaluation</li>
<li>Comparison with Sklearn model</li>
<li>Conclusion</li>
</ol>
<h3 id="importing-libraries">Importing libraries</h3>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
<span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">pandas</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">pd</span>
<span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">matplotlib.pyplot</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">plt</span>
</code></pre></div><h2 id="1dataset">1.Dataset</h2>
<p>The dataset is constituted of “YearsExperience” and “Salary” informations for 30 employees in an anonymous company.<!-- raw HTML omitted --></p>
<p>Get the original dataset here: <a href="https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression">https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression</a></p>
<h3 id="importing-dataset">Importing dataset</h3>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df = pd.read_csv(<span style="color:#cd5555">&#34;data/Salary_Data.csv&#34;</span>, delimiter= <span style="color:#cd5555">&#39;,&#39;</span>)
</code></pre></div><p>A simple dataframe visualization using markdown format:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">tabulate</span>
<span style="color:#8b008b;font-weight:bold">print</span>(df.head(<span style="color:#b452cd">7</span>).to_markdown())
</code></pre></div><pre><code>|    |   YearsExperience |   Salary |
|---:|------------------:|---------:|
|  0 |               1.1 |    39343 |
|  1 |               1.3 |    46205 |
|  2 |               1.5 |    37731 |
|  3 |               2   |    43525 |
|  4 |               2.2 |    39891 |
|  5 |               2.9 |    56642 |
|  6 |               3   |    60150 |
</code></pre>
<p>A better visualization for this blog is done by exporting dataframe visualization to png format:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#228b22">#!pip install dataframe-image</span>
<span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">dataframe_image</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">dfi</span>

<span style="color:#228b22"># I export the dataframe visualization as png</span>
<span style="color:#228b22"># so I can use markdown to show down the dataframe</span>
dfi.export(df.head(<span style="color:#b452cd">7</span>), <span style="color:#cd5555">&#34;img/linear_regression_dataframe.png&#34;</span>)
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/linear_regression_dataframe.png#c" alt="png"></p>
<h3 id="data-visualization">Data visualization</h3>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#228b22">#setting plots background color</span>
plt.rcParams.update({<span style="color:#cd5555">&#39;axes.facecolor&#39;</span>:<span style="color:#cd5555">&#39;#f8fafc&#39;</span>})
</code></pre></div><div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df.plot.scatter(<span style="color:#cd5555">&#39;YearsExperience&#39;</span>, <span style="color:#cd5555">&#39;Salary&#39;</span>,
                figsize=(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">6</span>), color=<span style="color:#cd5555">&#39;darkorange&#39;</span>,
                marker=<span style="color:#cd5555">&#39;o&#39;</span>, edgecolor=<span style="color:#cd5555">&#39;k&#39;</span>, s=<span style="color:#b452cd">100</span>)
plt.xlabel(<span style="color:#cd5555">&#39;Years Experience&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.ylabel(<span style="color:#cd5555">&#39;Annual Salary (USD)&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.title(<span style="color:#cd5555">&#39;Annual Salary v/s Years of Experience&#39;</span>, fontsize = <span style="color:#b452cd">15</span>)
plt.show()
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/output_19_0.png#c" alt="png"></p>
<p>One can see on plot that annual salaries of employees looks linearly correlated to years of experience !</p>
<h2 id="2linear-model-definition">2.Linear model definition</h2>
<p>In statistics, linear regression is a linear approach to modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables). The case of one explanatory variable is called simple linear regression.</p>
<p>Let&rsquo;s define <strong>y</strong> as the real random variable to be explained (dependent) and <strong>x</strong> the explanatory variable (independent). The model supposes that on average, <strong>y</strong> is an affine function of <strong>x</strong>. The writing of the model implicitly supposes a preliminary notion of causality in the sense that <strong>y</strong> depends on <strong>x</strong>:</p>
<p>For a given sequence of <strong>m</strong> observations</p>
<p>$${(x_i, y_i) \hspace{4mm}i=1 &hellip;, m}$$</p>
<p>$$ y_i=\beta_{0} +\beta_{1}.x_i + \epsilon_i $$</p>
<p>$$ Using \hspace{3mm}matrix \hspace{3mm}notations \hspace{3mm}x = [x_1, x_2, &hellip;, x_m]^T \hspace{3mm} and \hspace{3mm}  y = [y_1, y_2, &hellip;, y_m]^T$$</p>
<p>$$The \hspace{3mm}model \hspace{3mm}is:\hspace{3mm} y = X.\beta + \epsilon$$</p>
<p>$$Where\hspace{3mm} X = [1 \hspace{3mm} x] \hspace{3mm}and\hspace{3mm} \beta= [\beta_{0} \hspace{3mm}\beta_{1}]^T$$</p>
<p>The goal is to find the parameters which would provide the &ldquo;best&rdquo; fit in some sense for the data points:</p>
<p>$$ \hat{y_i}=\hat{\beta_{0}} +\hat{\beta_{1}}.x_i $$</p>
<h3 id="converting-data-into-arrays">Converting data into arrays</h3>
<p>To do calculations, we need to convert our data into arrays that will feed our custom model&hellip;</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x = df[<span style="color:#cd5555">&#34;YearsExperience&#34;</span>].values.reshape(-<span style="color:#b452cd">1</span>, <span style="color:#b452cd">1</span>)
y = df[<span style="color:#cd5555">&#34;Salary&#34;</span>].values.reshape(-<span style="color:#b452cd">1</span>, <span style="color:#b452cd">1</span>)
<span style="color:#8b008b;font-weight:bold">print</span>(x.shape, y.shape)
</code></pre></div><pre><code>(30, 1) (30, 1)
</code></pre>
<p>&hellip;And add identity column vector to feature:</p>
<p>$$X = [1 \hspace{3mm} x]$$</p>
<p>in order to do the product:</p>
<p>$$X.\beta \hspace{3mm}where\hspace{3mm}\beta= [\beta_{0} \hspace{3mm}\beta_{1}]^T$$</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X = np.hstack((np.ones(x.shape), x))
X[<span style="color:#b452cd">0</span>:<span style="color:#b452cd">5</span>]
</code></pre></div><pre><code>array([[1. , 1.1],
       [1. , 1.3],
       [1. , 1.5],
       [1. , 2. ],
       [1. , 2.2]])
</code></pre>
<h3 id="defining-model">Defining model</h3>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">model</span>(X, Beta):
    <span style="color:#8b008b;font-weight:bold">return</span> np.matmul(X, Beta)
</code></pre></div><h3 id="parameters-initialization">Parameters initialization</h3>
<p>For visualization purpose, I added a constant value to Beta initial values.</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Beta = np.random.randn(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>) + <span style="color:#b452cd">10000</span>
<span style="color:#8b008b;font-weight:bold">print</span>(Beta)
</code></pre></div><pre><code>[[10000.63920093]
 [ 9999.95848202]]
</code></pre>
<h3 id="checking-models-initial-state">Checking model&rsquo;s initial state</h3>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y_init = model(X, Beta)
</code></pre></div><div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt.figure(figsize=(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">6</span>))

plt.plot(x, y_init, label=<span style="color:#cd5555">&#39;Custom model initial state&#39;</span>,
         c= <span style="color:#cd5555">&#39;purple&#39;</span>, marker=<span style="color:#cd5555">&#39;None&#39;</span>, linestyle= <span style="color:#cd5555">&#39;solid&#39;</span>)
plt.scatter(x, y, c= <span style="color:#cd5555">&#39;darkorange&#39;</span>, label=<span style="color:#cd5555">&#39;Dataset&#39;</span>, marker=<span style="color:#cd5555">&#39;o&#39;</span>, edgecolor=<span style="color:#cd5555">&#39;k&#39;</span>, s=<span style="color:#b452cd">100</span>)
plt.legend(facecolor=<span style="color:#cd5555">&#39;white&#39;</span>)
plt.title(<span style="color:#cd5555">&#39;Annual Salary v/s Years of Experience&#39;</span>, fontsize = <span style="color:#b452cd">15</span>)
plt.xlabel(<span style="color:#cd5555">&#39;Years Experience&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.ylabel(<span style="color:#cd5555">&#39;Annual Salary (USD)&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.xticks(np.arange(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">1</span>))
plt.yticks(np.arange(<span style="color:#b452cd">20000</span>, <span style="color:#b452cd">140000</span>, <span style="color:#b452cd">10000</span>))
plt.grid(linestyle=<span style="color:#cd5555">&#39;--&#39;</span>)

plt.show()
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/output_47_0.png#c" alt="png"></p>
<p>One clearly see that the model is not yet fitted to our data.</p>
<h2 id="3loss-function-definition-using-mean-squared-error-mse">3.Loss function definition using Mean Squared Error (MSE)</h2>
<p>From the previous equations, we know that the residuals are defined by:</p>
<p>$$ \epsilon = y - X.\beta$$</p>
<p>Then to measure the error of our model we define the Loss function as the mean of the squares of the residuals:</p>
<p>$$ J(\beta) = \frac{1}{m} \sum (y - X.\beta)^2 $$</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">lossFunction</span>(X, y, Beta):
        m = y.shape[<span style="color:#b452cd">0</span>] <span style="color:#228b22"># where m is the number of samples</span>
        <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#b452cd">1</span>/(m) * np.sum(np.square(y - model(X, Beta)))
</code></pre></div><p>The Loss is the value that we want to minimize in order to find the best regression line. Let&rsquo;s check the initial Loss value:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">print</span>(lossFunction(X, y, Beta))
</code></pre></div><pre><code>199243474.14642814
</code></pre>
<p>Notice the high value of our Loss !! It can be possible to scale the values of the x feature in order to reduce the high values during the calculations &hellip; but for this try we can stay with non scaled values.</p>
<h2 id="4gradient-definition">4.Gradient definition</h2>
<p>Now we calculate the gradient of the Loss function:</p>
<p>$$\frac{\partial J(\beta) }{\partial \beta} = - \frac{2}{m} X^T.(y - X.\beta)$$</p>
<p>But as we want to solve a minimization problem, we keep for calculations the gradient multiplied by -1:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">gradient</span>(X, y, Beta):
    m = y.shape[<span style="color:#b452cd">0</span>]
    <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#b452cd">2</span>/m * np.matmul(X.T, model(X, Beta) - y)
</code></pre></div><p>Minimizing the Loss function means that its final gradient should be close to zero. Let&rsquo;s check the initial values of the gradient:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">print</span>(gradient(X, y, Beta))
</code></pre></div><pre><code>[[ -25738.49612919]
 [-128193.59810319]]
</code></pre>
<h2 id="5gradient-descent-algorithm">5.Gradient descent algorithm</h2>
<p>For each iteration of the calculus we update the parameters as well as the gradient of the model using the gradient descent algorithm:</p>
<p>$$\beta' = \beta - \alpha \frac{\partial J(\beta) }{\partial \beta}$$</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">gradientDescent</span>(X, y, Beta, learning_rate, n_iterations):
    loss_history = np.zeros(n_iterations)
    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(n_iterations):
        Beta = Beta - learning_rate * gradient(X, y, Beta)
        loss_history[i] = lossFunction(X, y, Beta)
    
    <span style="color:#8b008b;font-weight:bold">return</span> Beta, loss_history, gradient(X, y , Beta)
</code></pre></div><h2 id="6training-the-model-on-data">6.Training the model on data</h2>
<p>Fisrt I define the hypermarameters:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">N_ITERATIONS = <span style="color:#b452cd">20000</span>
LEARNING_RATE = <span style="color:#b452cd">0.001</span>
</code></pre></div><p>Then I train the model on the data&hellip;</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Final_Beta, loss_history, Final_gradient = gradientDescent(X, y, Beta, LEARNING_RATE, N_ITERATIONS)
</code></pre></div><p>&hellip; check the final values of the gradient (closer to zero as expected !) &hellip;</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">print</span>(Final_gradient)
</code></pre></div><pre><code>[[-1.38763209]
 [ 0.20591879]]
</code></pre>
<p>&hellip; and get the final regression coefficients:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#34;Intercept = {Final_Beta[0][0]:.2f}&#34;</span>)
<span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#34;coefficient = {Final_Beta[1][0]:.2f}&#34;</span>)
</code></pre></div><pre><code>Intercept = 25788.92
coefficient = 9450.45
</code></pre>
<p>Let&rsquo;s have a look on the Learning Curve:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt.figure(figsize=(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">6</span>))
plt.plot(<span style="color:#658b00">range</span>(N_ITERATIONS), loss_history, c= <span style="color:#cd5555">&#39;purple&#39;</span>)
plt.title(<span style="color:#cd5555">&#39;Learning curve&#39;</span>, fontsize = <span style="color:#b452cd">15</span>)
plt.xlabel(<span style="color:#cd5555">&#39;Iterations&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.ylabel(<span style="color:#cd5555">&#39;Loss value&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.show()
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/output_79_0.png#c" alt="png"></p>
<h2 id="7model-evaluation">7.Model evaluation</h2>
<h3 id="regression-line-visualization">Regression line visualization</h3>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y_pred_custom = model(X, Final_Beta)
</code></pre></div><p>Let&rsquo;s have a look on the regression line:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt.figure(figsize=(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">6</span>))

plt.plot(x, y_pred_custom, label=<span style="color:#cd5555">&#39;Custom model prediction&#39;</span>,
         c= <span style="color:#cd5555">&#39;purple&#39;</span>, marker=<span style="color:#cd5555">&#39;None&#39;</span>, linestyle= <span style="color:#cd5555">&#39;solid&#39;</span>)
plt.scatter(x, y, c= <span style="color:#cd5555">&#39;darkorange&#39;</span>, label=<span style="color:#cd5555">&#39;Dataset&#39;</span>, marker=<span style="color:#cd5555">&#39;o&#39;</span>, edgecolor=<span style="color:#cd5555">&#39;k&#39;</span>, s=<span style="color:#b452cd">100</span>)
plt.legend(facecolor=<span style="color:#cd5555">&#39;white&#39;</span>, loc=<span style="color:#cd5555">&#34;upper left&#34;</span>)
plt.title(<span style="color:#cd5555">&#39;Annual Salary v/s Years of Experience&#39;</span>, fontsize = <span style="color:#b452cd">15</span>)
plt.xlabel(<span style="color:#cd5555">&#39;Years Experience&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.ylabel(<span style="color:#cd5555">&#39;Annual Salary (USD)&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.xticks(np.arange(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">1</span>))
plt.yticks(np.arange(<span style="color:#b452cd">30000</span>, <span style="color:#b452cd">140000</span>, <span style="color:#b452cd">10000</span>))
plt.grid(linestyle=<span style="color:#cd5555">&#39;--&#39;</span>)

plt.show()
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/output_84_0.png#c" alt="png"></p>
<p>We can see on plot that this time the model fits pretty good on the data !</p>
<h3 id="salary-estimation">Salary estimation</h3>
<p>Now let&rsquo;s imagine that we want to have an estimation of the salary for someone who have 12 years of experience in the company.</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x_estimation = np.array([<span style="color:#b452cd">12</span>])
X_estimation = np.hstack((np.ones(x_estimation.shape), x_estimation))
y_estimation = model(X_estimation, Final_Beta)

<span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#39;The estimated annual salary of someone who has 12 years of experience is </span><span style="color:#cd5555">\
</span><span style="color:#cd5555"></span><span style="color:#cd5555">{y_estimation[0]:.0f} USD </span><span style="color:#cd5555">\n</span><span style="color:#cd5555">... according to our dataset.&#39;</span>)
</code></pre></div><pre><code>The estimated annual salary of someone who has 12 years of experience is 139194 USD 
... according to our dataset.
</code></pre>
<p>Let&rsquo;s visualize the result on the plot:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt.figure(figsize=(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">6</span>))

plt.scatter(x_estimation, y_estimation, label=<span style="color:#cd5555">&#39;Estimation&#39;</span>,
            c= <span style="color:#cd5555">&#39;yellowgreen&#39;</span>, marker=<span style="color:#cd5555">&#39;o&#39;</span>, edgecolor=<span style="color:#cd5555">&#39;k&#39;</span>, s=<span style="color:#b452cd">200</span>)
plt.plot(x, y_pred_custom, label=<span style="color:#cd5555">&#39;Custom model prediction&#39;</span>,
         c= <span style="color:#cd5555">&#39;purple&#39;</span>, marker=<span style="color:#cd5555">&#39;None&#39;</span>, linestyle= <span style="color:#cd5555">&#39;solid&#39;</span>)
plt.scatter(x, y, c= <span style="color:#cd5555">&#39;darkorange&#39;</span>, label=<span style="color:#cd5555">&#39;Dataset&#39;</span>, marker=<span style="color:#cd5555">&#39;o&#39;</span>, edgecolor=<span style="color:#cd5555">&#39;k&#39;</span>, s=<span style="color:#b452cd">100</span>)
plt.legend(facecolor=<span style="color:#cd5555">&#39;white&#39;</span>, loc=<span style="color:#cd5555">&#34;upper left&#34;</span>)
plt.title(<span style="color:#cd5555">&#39;Annual Salary v/s Years of Experience&#39;</span>, fontsize = <span style="color:#b452cd">15</span>)
plt.xlabel(<span style="color:#cd5555">&#39;Years Experience&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.ylabel(<span style="color:#cd5555">&#39;Annual Salary (USD)&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.xticks(np.arange(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">13</span>, <span style="color:#b452cd">1</span>))
plt.yticks(np.arange(<span style="color:#b452cd">30000</span>, <span style="color:#b452cd">150000</span>, <span style="color:#b452cd">10000</span>))
plt.grid(linestyle=<span style="color:#cd5555">&#39;--&#39;</span>)

plt.show()
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/output_90_0.png#c" alt="png"></p>
<p>One can see on plot the estimated salary for someone who has 12 years of experience in the company.</p>
<h3 id="coefficient-of-determination">Coefficient of determination</h3>
<p>This coefficient indicates the quality of predictions made with our model.</p>
<p>$$ R^2 = 1 - \frac{\sum ((y_i - \hat{y_i})^2}{\sum ((y_i - \bar{y})^2)} $$</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">determinationCoef</span>(y, y_pred):
    SSR = ((y - y_pred)**<span style="color:#b452cd">2</span>).sum()    <span style="color:#228b22"># Residual sum of squares SSR</span>
    SST = ((y - y.mean())**<span style="color:#b452cd">2</span>).sum()  <span style="color:#228b22"># Total sum of squares SST</span>
    <span style="color:#8b008b;font-weight:bold">return</span> np.sqrt(<span style="color:#b452cd">1</span> - SSR/SST)
</code></pre></div><div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#34;R2 = {determinationCoef(y, y_pred_custom):0.2f}&#34;</span>)
</code></pre></div><pre><code>R2 = 0.98
</code></pre>
<p>We almost reach the maximum value of 1 !! The model can estimate accuratly any salary given the number of years of experience of an employee in the company.</p>
<h2 id="8comparison-with-sklearn-linearregression-model">8.Comparison with sklearn LinearRegression model</h2>
<p>Scikit-Learn already provides a well built Linear Regression model for general purpose (linear, multi-linear or polynomial regressions). <!-- raw HTML omitted -->
I will apply it on the Salary_data.csv dataset in order to compare and check the quality of my custom linear regression model.</p>
<p>As I&rsquo;ve done previously, I define X, y variables</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X = df.iloc[:, :-<span style="color:#b452cd">1</span>].values
y = df.iloc[:, -<span style="color:#b452cd">1</span>].values.reshape(-<span style="color:#b452cd">1</span>, <span style="color:#b452cd">1</span>)
<span style="color:#8b008b;font-weight:bold">print</span>(X.shape, y.shape)
</code></pre></div><pre><code>(30, 1) (30, 1)
</code></pre>
<p>Next I define a linear regression model using Sklearn library&hellip;</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">sklearn.linear_model</span> <span style="color:#8b008b;font-weight:bold">import</span> LinearRegression
LR_model = LinearRegression()
</code></pre></div><p>&hellip;fit the model to the data&hellip;</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">LR_model.fit(X, y)
</code></pre></div><pre><code>LinearRegression()
</code></pre>
<p>&hellip;and get the resulting regression coefficients</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#34;Intercept = {LR_model.intercept_[0]:.2f}&#34;</span>)
<span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#34;coefficient = {LR_model.coef_[0][0]:.2f}&#34;</span>)
</code></pre></div><pre><code>Intercept = 25792.20
coefficient = 9449.96
</code></pre>
<p>Now let&rsquo;s see how well the model fits to the data</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y_pred_sklearn = LR_model.predict(X)
</code></pre></div><div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt.figure(figsize=(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">6</span>))

plt.plot(X, y_pred_sklearn, label=<span style="color:#cd5555">&#39;Sklearn model prediction&#39;</span>,
         c= <span style="color:#cd5555">&#39;darkturquoise&#39;</span>, marker=<span style="color:#cd5555">&#39;None&#39;</span>, linestyle= <span style="color:#cd5555">&#39;solid&#39;</span>)
plt.scatter(X, y, c= <span style="color:#cd5555">&#39;darkorange&#39;</span>, label=<span style="color:#cd5555">&#39;Dataset&#39;</span>, marker=<span style="color:#cd5555">&#39;o&#39;</span>, edgecolor=<span style="color:#cd5555">&#39;k&#39;</span>, s=<span style="color:#b452cd">100</span>)
plt.legend(facecolor=<span style="color:#cd5555">&#39;white&#39;</span>, loc=<span style="color:#cd5555">&#34;upper left&#34;</span>)
plt.title(<span style="color:#cd5555">&#39;Annual Salary v/s Years of Experience&#39;</span>, fontsize = <span style="color:#b452cd">15</span>)
plt.xlabel(<span style="color:#cd5555">&#39;Years Experience&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.ylabel(<span style="color:#cd5555">&#39;Annual Salary (USD)&#39;</span>, fontsize = <span style="color:#b452cd">12</span>)
plt.xticks(np.arange(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">1</span>))
plt.yticks(np.arange(<span style="color:#b452cd">30000</span>, <span style="color:#b452cd">140000</span>, <span style="color:#b452cd">10000</span>))
plt.grid(linestyle=<span style="color:#cd5555">&#39;--&#39;</span>)

plt.show()
</code></pre></div><p><img src="https://domsdev.github.io/Data-science-blog/images/A_Simple_Linear_Regression_from_scratch/2020-09-09/output_110_0.png#c" alt="png"></p>
<p>Salary estimation:</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_estimation = np.array([<span style="color:#b452cd">12</span>]).reshape(-<span style="color:#b452cd">1</span>,<span style="color:#b452cd">1</span>)
y_estimation = LR_model.predict(X_estimation)

<span style="color:#8b008b;font-weight:bold">print</span>(f<span style="color:#cd5555">&#39;The estimated annual salary of someone who has 12 years of experience is </span><span style="color:#cd5555">\
</span><span style="color:#cd5555"></span><span style="color:#cd5555">{y_estimation[0][0]:.0f} USD&#39;</span>)
</code></pre></div><pre><code>The estimated annual salary of someone who has 12 years of experience is 139192 USD
</code></pre>
<h2 id="9conclusion">9.Conclusion</h2>
<p><strong>The custom model build from scratch looks pretty good to predict salary given years of experience and fits pretty well to the data, thus I get a R2 determination coefficient of 0.98 (almost 1) that indicates a good quality of predictions.</strong></p>
<p><strong>Comparing coefficients of regression and estimated salaries for both models, one can see that the custom model gives the same results as the Sklearn model.</strong></p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">tabulate</span>
<span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">pandas</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">pd</span>
results = {
    <span style="color:#cd5555">&#39;Model&#39;</span>: [<span style="color:#cd5555">&#34;Custom LR model&#34;</span>, <span style="color:#cd5555">&#39;Sklearn LR model&#39;</span>],
    <span style="color:#cd5555">&#39;Intercetp&#39;</span>: [<span style="color:#b452cd">25788.92</span>, <span style="color:#b452cd">25792.20</span>],
    <span style="color:#cd5555">&#39;coefficient&#39;</span>: [<span style="color:#b452cd">9450.45</span>, <span style="color:#b452cd">9449.96</span>],
    <span style="color:#cd5555">&#39;12 Years exp. estimated Ann. Salary&#39;</span>: [<span style="color:#b452cd">139194</span>, <span style="color:#b452cd">139192</span>]}

df_results = pd.DataFrame(data=results).set_index(<span style="color:#cd5555">&#39;Model&#39;</span>)
<span style="color:#8b008b;font-weight:bold">print</span>(df_results.to_markdown())
</code></pre></div><pre><code>| Model            |   Intercetp |   coefficient |   12 Years exp. estimated Ann. Salary |
|:-----------------|------------:|--------------:|--------------------------------------:|
| Custom LR model  |     25788.9 |       9450.45 |                                139194 |
| Sklearn LR model |     25792.2 |       9449.96 |                                139192 |
</code></pre>
<p><strong>Now we have a rather precise tool which can help human resources to estimate the annual salary of an employee of this anonymous company according to his number of experience in this company.</strong></p>
      
      <div class="related">
</div>
      
    </div>
    
  </div>
</section>

    <script src="https://domsdev.github.io/Data-science-blog/js/copycode.js"></script>



<section class="section">
  <div class="container has-text-centered">
    <p>&copy; <a href="https://github.com/Domsdev/Data-science-blog/blob/main/MIT%20Licence.md">DomsDev</a></p>
    
      <p>Powered by<a href="https://gohugo.io/">Hugo</a>static site generator &amp; <a href="https://github.com/ribice/kiss">Kiss</a>theme.</p>
    
  </div>
</section>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-NMH2VJY863', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script type="text/javascript">
  var _paq = _paq || [];
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="\/\/matomo.example.com\/";
    _paq.push(['setTrackerUrl', u+'piwik.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<noscript>
  <img src="//matomo.example.com/piwik.php?idsite=1&amp;rec=1" style="border:0" alt="">
</noscript>

<script>
    (function(f, a, t, h, o, m){
        a[h]=a[h]||function(){
            (a[h].q=a[h].q||[]).push(arguments)
        };
        o=f.createElement('script'),
        m=f.getElementsByTagName('script')[0];
        o.async=1; o.src=t; o.id='fathom-script';
        m.parentNode.insertBefore(o,m)
    })(document, window, '\/\/fathom.example.com\/tracker.js', 'fathom');
    fathom('trackPageview');
</script>


</body>
</html>

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

